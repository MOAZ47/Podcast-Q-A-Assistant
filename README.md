# ğŸ™ï¸ Podcast Q&A Assistant with Multimodal RAG + Agentic AI Framework

A Multimodal LLM Agentic AI application that allows users to upload podcast/audio files, transcribes them using Whisper, summarizes the content, fact-checks the claims using an LLM + internet search, and delivers a clear, confidence-rated report â€” all through a modular multi-agent pipeline.

---

## ğŸš€ Features

âœ… Upload and analyze any podcast/audio file  
âœ… Automatic transcription using OpenAI Whisper  
âœ… Summary generation via LLM  
âœ… Claim-level fact-checking using external evidence  
âœ… Agent-based architecture: transcriber, summarizer, fact-checker, reporter  
âœ… Interactive Streamlit UI  
âœ… Few-shot prompting with example control  
âœ… Session memory, rerun/reset support  
âœ… Modular codebase for easy scaling

---

## ğŸ“¦ Tech Stack

| Component       | Technology                                |
|------------------|--------------------------------------------|
| Transcription    | [OpenAI Whisper](https://github.com/openai/whisper) |
| LLM              | [Cohere LLM](https://cohere.com) via LangChain |
| Fact Checking    | Custom agent using LLM + external search   |
| Vector Store     | [Weaviate](https://weaviate.io/) (optional) |
| Prompting        | LangChain's `FewShotPromptTemplate`        |
| Frontend         | Streamlit                                  |
| Embeddings       | Sentence Transformers via HuggingFace      |

---

## ğŸ§  Architecture Overview

```plaintext
User Uploads Audio
        â”‚
        â–¼
[ Transcriber Agent ]  â† Whisper
        â”‚
        â–¼
[ Summarizer Agent ]   â† LLM (Cohere or others)
        â”‚
        â–¼
[ Fact-Checker Agent ] â† LLM + Internet
        â”‚
        â–¼
[ Reporter Agent ]     â† Few-shot LLM Report Generation
        â”‚
        â–¼
Streamlit UI â†’ Transcript + Final Report

```

---

## Installation
```bash
git clone https://github.com/Moaz47/Podcast-Q-A-Assistant.git
cd agentic-audio-rag

# Optional: set up a virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```
---

## Running the code
```bash
streamlit run app.py

```

---

## ğŸ“ Project Structure
```plaintext
.
â”œâ”€â”€ app.py               # Streamlit app UI
â”œâ”€â”€ main.py              # Orchestrates the pipeline
â”œâ”€â”€ config.py            # API keys
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ transcription.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ factchecker.py
â”‚   â””â”€â”€ reporter.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```
---

## âœ¨ Future Improvements
<ul>
    <li>Add chat interface for user questions over the podcast. </li>
    <li>Exportable PDF reports. </li>
    <li>Multi-turn memory for user corrections. </li>
    <li>OpenAI / Gemini model switching. </li>
</ul>